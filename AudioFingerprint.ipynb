{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CurrentDemoUnmix.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ttSgu0TLZNNI",
        "cqBqCAw3ZUiw"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nindidooo/MODA/blob/main/AudioFingerprint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7xZSaW3ZCfY"
      },
      "source": [
        "## Setup Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKtUhuHoQlgR",
        "outputId": "ff40fa19-5517-4fa3-a35a-70d14af6a123"
      },
      "source": [
        "#@title Setup the google drive\n",
        "#Choose songs to split/analyse\n",
        "songs = ['Vanilla-Ice-Ice-Ice-Baby', 'Queen-Under-Pressure']\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=False)\n",
        "\n",
        "root = '/content/gdrive/MyDrive/audio_files/Unmix Demo/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urm-Y3cIRBel",
        "outputId": "f4efa685-7900-4dab-e284-fb7b7e26c8bd"
      },
      "source": [
        "#@title installs and configuration\\\n",
        "#Unmix\n",
        "!pip install openunmix\n",
        "\n",
        "#Magenta\n",
        "!pip install --upgrade tensorflow\n",
        "!pip install --upgrade librosa\n",
        "import glob\n",
        "\n",
        "print('Copying checkpoints from GCS...')\n",
        "!rm -r /content/onsets-frames\n",
        "!mkdir /content/onsets-frames\n",
        "!gsutil -q -m cp -R gs://magentadata/models/onsets_frames_transcription/*checkpoint*.zip /content/onsets-frames/\n",
        "!unzip -o /content/onsets-frames/maestro_checkpoint.zip -d /content/onsets-frames/maestro\n",
        "MAESTRO_CHECKPOINT_DIR = '/content/onsets-frames/maestro/train'\n",
        "!unzip -o /content/onsets-frames/e-gmd_checkpoint.zip -d /content/onsets-frames/e-gmd\n",
        "EGMD_CHECKPOINT_DIR = '/content/onsets-frames/e-gmd'\n",
        "  \n",
        "print('Installing dependencies...')\n",
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev ffmpeg  \n",
        "!pip install pyfluidsynth pretty_midi\n",
        "\n",
        "!pip install -qU magenta\n",
        "\n",
        "#Feature Extraction\n",
        "!pip install music21\n",
        "!pip install MIDIFile"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting openunmix\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/3d/1e6bb39d86c818fbf638566bb5496404ca9623462b9695e0abc92c648349/openunmix-1.1.2-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openunmix) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from openunmix) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from openunmix) (1.9.0+cu102)\n",
            "Collecting torchaudio>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/20/eab40caad8f4b97f5e91a5de8ba5ec29115e08fa4c9a808725490b7b4844/torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 13.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.0->openunmix) (3.7.4.3)\n",
            "Installing collected packages: torchaudio, openunmix\n",
            "Successfully installed openunmix-1.1.2 torchaudio-0.9.0\n",
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied, skipping upgrade: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.34.1)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.31.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow) (4.5.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.4.1)\n",
            "Requirement already up-to-date: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied, skipping upgrade: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied, skipping upgrade: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.14.5)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied, skipping upgrade: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.20)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (1.24.3)\n",
            "Copying checkpoints from GCS...\n",
            "rm: cannot remove '/content/onsets-frames': No such file or directory\n",
            "Archive:  /content/onsets-frames/maestro_checkpoint.zip\n",
            "   creating: /content/onsets-frames/maestro/train/\n",
            "  inflating: /content/onsets-frames/maestro/train/model.ckpt.data-00000-of-00001  \n",
            "  inflating: /content/onsets-frames/maestro/train/model.ckpt.meta  \n",
            "  inflating: /content/onsets-frames/maestro/train/model.ckpt.index  \n",
            "  inflating: /content/onsets-frames/maestro/train/checkpoint  \n",
            "Archive:  /content/onsets-frames/e-gmd_checkpoint.zip\n",
            "  inflating: /content/onsets-frames/e-gmd/checkpoint  \n",
            "  inflating: /content/onsets-frames/e-gmd/model.ckpt-569400.data-00000-of-00001  \n",
            "  inflating: /content/onsets-frames/e-gmd/model.ckpt-569400.index  \n",
            "  inflating: /content/onsets-frames/e-gmd/model.ckpt-569400.meta  \n",
            "Installing dependencies...\n",
            "Selecting previously unselected package fluid-soundfont-gm.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../fluid-soundfont-gm_3.1-5.1_all.deb ...\n",
            "Unpacking fluid-soundfont-gm (3.1-5.1) ...\n",
            "Selecting previously unselected package libfluidsynth1:amd64.\n",
            "Preparing to unpack .../libfluidsynth1_1.1.9-1_amd64.deb ...\n",
            "Unpacking libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Setting up fluid-soundfont-gm (3.1-5.1) ...\n",
            "Setting up libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting pyfluidsynth\n",
            "  Downloading https://files.pythonhosted.org/packages/d9/82/f44dd62e78c53a61c7bebca401d92646b0556595ff9049130c545f4d57d9/pyFluidSynth-1.3.0-py3-none-any.whl\n",
            "Collecting pretty_midi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/8e/63c6e39a7a64623a9cd6aec530070c70827f6f8f40deec938f323d7b1e15/pretty_midi-0.2.9.tar.gz (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 10.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyfluidsynth) (1.19.5)\n",
            "Collecting mido>=1.1.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/6d/e18a5b59ff086e1cd61d7fbf943d86c5f593a4e68bfc60215ab74210b22b/mido-1.2.10-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pretty_midi) (1.15.0)\n",
            "Building wheels for collected packages: pretty-midi\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty-midi: filename=pretty_midi-0.2.9-cp37-none-any.whl size=5591958 sha256=b064accd5406e4a963137d5154e73352697834e247aec5d8ac5aafe1273df477\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/a1/c6/b5697841db1112c6e5866d75a6b6bf1bef73b874782556ba66\n",
            "Successfully built pretty-midi\n",
            "Installing collected packages: pyfluidsynth, mido, pretty-midi\n",
            "Successfully installed mido-1.2.10 pretty-midi-0.2.9 pyfluidsynth-1.3.0\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 7.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 256kB 33.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5MB 37.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 12.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 49.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 47.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 215kB 55.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.6MB 52.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3MB 51.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6MB 50.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 9.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 686kB 40.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 12.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 57.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 368kB 42.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.6MB 26.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 655kB 38.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 368kB 46.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.2MB 1.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 256kB 57.2MB/s \n",
            "\u001b[?25h  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-rtmidi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypng (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: kfac 0.2.3 has requirement tensorflow-probability==0.8, but you'll have tensorflow-probability 0.12.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensor2tensor 1.15.7 has requirement tensorflow-probability==0.7.0, but you'll have tensorflow-probability 0.12.1 which is incompatible.\u001b[0m\n",
            "Requirement already satisfied: music21 in /usr/local/lib/python3.7/dist-packages (5.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttSgu0TLZNNI"
      },
      "source": [
        "## Unmix Separation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBRJ0MtS-Wrg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37e6cc91-a09e-46ab-9c5d-74534f91a022"
      },
      "source": [
        "import os\n",
        "for song in songs:\n",
        "  os.chdir(root + song)\n",
        "  isSuccess = os.system('umx \"' + song + '.wav\" ' + '--model umxhq')\n",
        "  if(isSuccess != 0):\n",
        "    print(\"Something went wrong separating files, restart runtime and try again\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a049c750e207>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msong\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msongs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0misSuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'umx \"'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msong\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.wav\" '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'--model umxhq'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misSuccess\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/audio_files/Unmix Demo/Vanilla-Ice-Ice-Ice-Baby'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqBqCAw3ZUiw"
      },
      "source": [
        "## Midi Creation through Magenta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96L8BN-Pds5J"
      },
      "source": [
        "#@title Select Magenta Model\n",
        "model_type = \"MAESTRO (Piano)\" #@param [\"MAESTRO (Piano)\", \"E-GMD (Drums)\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X13S_-moXcn_"
      },
      "source": [
        "#@title Initialize Magenta Model\n",
        "import tensorflow.compat.v1 as tf\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "from magenta.common import tf_utils\n",
        "from note_seq import audio_io\n",
        "from magenta.models.onsets_frames_transcription import audio_label_data_utils\n",
        "from magenta.models.onsets_frames_transcription import configs\n",
        "from magenta.models.onsets_frames_transcription import constants\n",
        "from magenta.models.onsets_frames_transcription import data\n",
        "from magenta.models.onsets_frames_transcription import infer_util\n",
        "from magenta.models.onsets_frames_transcription import train_util\n",
        "import note_seq\n",
        "from note_seq import midi_io\n",
        "from note_seq import sequences_lib\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "## Define model and load checkpoint\n",
        "## Only needs to be run once.\n",
        "\n",
        "if model_type.startswith('MAESTRO'):\n",
        "  config = configs.CONFIG_MAP['onsets_frames']\n",
        "  hparams = config.hparams\n",
        "  hparams.use_cudnn = False\n",
        "  hparams.batch_size = 1\n",
        "  checkpoint_dir = MAESTRO_CHECKPOINT_DIR\n",
        "elif model_type.startswith('E-GMD'):\n",
        "  config = configs.CONFIG_MAP['drums']\n",
        "  hparams = config.hparams\n",
        "  hparams.batch_size = 1\n",
        "  checkpoint_dir = EGMD_CHECKPOINT_DIR\n",
        "else:\n",
        "  raise ValueError('Unknown Model Type')\n",
        "\n",
        "examples = tf.placeholder(tf.string, [None])\n",
        "\n",
        "dataset = data.provide_batch(\n",
        "    examples=examples,\n",
        "    preprocess_examples=True,\n",
        "    params=hparams,\n",
        "    is_training=False,\n",
        "    shuffle_examples=False,\n",
        "    skip_n_initial_records=0)\n",
        "\n",
        "estimator = train_util.create_estimator(\n",
        "    config.model_fn, checkpoint_dir, hparams)\n",
        "\n",
        "iterator = tf.data.make_initializable_iterator(dataset)\n",
        "next_record = iterator.get_next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NadhyBvhUMeL"
      },
      "source": [
        "#@title Magenta midi creation { form-width: \"150px\" }\n",
        "from pydub import AudioSegment\n",
        "from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "def transcription_data(params):\n",
        "  del params\n",
        "  return tf.data.Dataset.from_tensors(sess.run(next_record))\n",
        "#print(f'uploaded {uploaded}')\n",
        "#for fn in uploaded.keys():\n",
        "directory = []\n",
        "# for d in directory:\n",
        "#   spl = d + '/Spleeter/'\n",
        "#   song = os.listdir(spl)\n",
        "#   print(f'arr: {song}')\n",
        "stems = ['vocals.wav', 'bass.wav', 'other.wav', 'drums.wav']\n",
        "#spl = './Vanilla-Ice-Ice-Ice-Baby-_Official-Music-Video__umxhq/'\n",
        "for song in songs:\n",
        "  os.chdir(root+song)\n",
        "  for stem in stems:\n",
        "    to_process = []\n",
        "    with open(song + '_umxhq/'+stem, mode='rb') as file: \n",
        "      wav_data = file.read()\n",
        "    #print('User uploaded file \"{name}\" with length {length} bytes'.format( name=fn, length=len(uploaded[fn])))\n",
        "    #wav_data = uploaded[fn]\n",
        "    #print(f'wav data {wav_data}')\n",
        "    example_list = list(audio_label_data_utils.process_record(\n",
        "            wav_data=wav_data,\n",
        "            sample_rate=hparams.sample_rate,\n",
        "            ns=note_seq.NoteSequence(),\n",
        "            example_id=stem,\n",
        "            min_length=0,\n",
        "            max_length=-1,\n",
        "            allow_empty_notesequence=True))\n",
        "    assert len(example_list) == 1\n",
        "    to_process.append(example_list[0].SerializeToString())\n",
        "    \n",
        "    #print('Processing complete for', fn)\n",
        "    \n",
        "    sess = tf.Session()\n",
        "\n",
        "    sess.run([\n",
        "        tf.initializers.global_variables(),\n",
        "        tf.initializers.local_variables()\n",
        "    ])\n",
        "\n",
        "    sess.run(iterator.initializer, {examples: to_process})\n",
        "\n",
        "    input_fn = infer_util.labels_to_features_wrapper(transcription_data)\n",
        "\n",
        "    prediction_list = list(\n",
        "      estimator.predict(\n",
        "          input_fn,\n",
        "          yield_single_examples=False))\n",
        "    assert len(prediction_list) == 1\n",
        "\n",
        "    sequence_prediction = note_seq.NoteSequence.FromString(\n",
        "        prediction_list[0]['sequence_predictions'][0])\n",
        "\n",
        "    # Ignore warnings caused by pyfluidsynth\n",
        "    import warnings\n",
        "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
        "    #print(f'sequence_prediction: {prediction_list[0]['sequence_predictions'][0][0]}')\n",
        "    \n",
        "\n",
        "    note_seq.plot_sequence(sequence_prediction)\n",
        "    note_seq.play_sequence(sequence_prediction, note_seq.midi_synth.fluidsynth,\n",
        "                    colab_ephemeral=False)\n",
        "    !ls\n",
        "    !mkdir {'./midi'}\n",
        "    midi_filename = ('./midi/' + stem[:-3] + 'mid')\n",
        "    print(f'midi_filename:  {midi_filename}')\n",
        "    midi_io.sequence_proto_to_midi_file(sequence_prediction, midi_filename)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH06Exb9jtIt"
      },
      "source": [
        "#@title determine key and transpose to C/Am\n",
        "import music21\n",
        "import os\n",
        "scale_normalisation_ignores = ['drums.mid']\n",
        "for song in songs:\n",
        "  os.chdir(root + song)\n",
        "  cur_path = root + song + '/midi'\n",
        "  file_names = os.listdir('./midi/')\n",
        "\n",
        "\n",
        "  #remove the drums.mid\n",
        "  for item in scale_normalisation_ignores:\n",
        "    if item in file_names:\n",
        "      file_names.remove(item)\n",
        "  file_names2 = file_names.copy()\n",
        "\n",
        "  #remove C_*.mid files\n",
        "  for item in file_names2: \n",
        "    if item.startswith('C_'):\n",
        "      file_names.remove(item)\n",
        "\n",
        "  print(f'arr: {file_names}')\n",
        "  highestKey = None\n",
        "  highestProbability = 0\n",
        "  #for stem in song:\n",
        "  for midi in file_names:\n",
        "    score = music21.converter.parse('./midi/' + midi)\n",
        "    key = score.analyze('Krumhansl')\n",
        "    print(f'Results for {song + midi}')\n",
        "    print(f'Key {key} has probability {key.correlationCoefficient}')\n",
        "    if (key.correlationCoefficient > highestProbability):\n",
        "      highestKey = key\n",
        "      highestProbability = key.correlationCoefficient\n",
        "    for altKey in key.alternateInterpretations:\n",
        "      if(altKey.correlationCoefficient < 0.5):\n",
        "        break\n",
        "      print(f'Key {altKey} has probability {altKey.correlationCoefficient}')\n",
        "\n",
        "  print(f'Most likely key for song {song[2:-14]} is {highestKey} with probability {highestProbability}')\n",
        "\n",
        "  print(f'Transposing midi to C/Am')\n",
        "  majors = dict([(\"A-\", 4),(\"A\", 3),(\"B-\", 2),(\"B\", 1),(\"C\", 0),(\"D-\", -1),(\"D\", -2),(\"E-\", -3),(\"E\", -4),(\"F\", -5),(\"G-\", 6),(\"G\", 5)])\n",
        "  minors = dict([(\"A-\", 1),(\"A\", 0),(\"B-\", -1),(\"B\", -2),(\"C\", -3),(\"D-\", -4),(\"D\", -5),(\"E-\", 6),(\"E\", 5),(\"F\", 4),(\"G-\", 3),(\"G\", 2)])\n",
        "  key = highestKey\n",
        "  #    print key.tonic.name, key.mode\n",
        "  if key.mode == \"major\":\n",
        "      halfSteps = majors[key.tonic.name]\n",
        "      \n",
        "  elif key.mode == \"minor\":\n",
        "      halfSteps = minors[key.tonic.name]\n",
        "\n",
        "  print(f'Transposing by {halfSteps}  semi-tones')\n",
        "  for midi in file_names:\n",
        "    score = music21.converter.parse('./midi/' + midi)\n",
        "    newscore = score.transpose(halfSteps)\n",
        "    #print key.tonic.name, key.mode\n",
        "    newFileName = \"./midi/C_\" + midi\n",
        "    newscore.write('midi',newFileName)\n",
        "    print(f'Transposed midi file saved at {newFileName} ')\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O683_UsRLvFT"
      },
      "source": [
        "#@title normalise midi to one octave\n",
        "import os\n",
        "for song in songs:\n",
        "  os.chdir(root + song)\n",
        "  file_names = os.listdir('./midi/')\n",
        "\n",
        "  #remove the drums.mid\n",
        "  for item in scale_normalisation_ignores:\n",
        "    if item in file_names:\n",
        "      file_names.remove(item)\n",
        "  file_names2 = file_names.copy()\n",
        "\n",
        "  #remove C_*.mid files\n",
        "  for item in file_names2: \n",
        "    if not item.startswith('C_'):\n",
        "      file_names.remove(item)\n",
        "\n",
        "  for midi in file_names:\n",
        "    print(f'Squish {midi} to one octave')\n",
        "    sequence_prediction = note_seq.midi_file_to_note_sequence('./midi/' + midi)\n",
        "    for i in range(len(sequence_prediction.notes)):\n",
        "      sequence_prediction.notes[i].pitch = sequence_prediction.notes[i].pitch % 12\n",
        "    \n",
        "    note_seq.note_sequence_to_midi_file(sequence_prediction, './midi/' + '0' + midi)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCN_Rw-QZf7b"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "argFSqfIa8M4"
      },
      "source": [
        "#@title Helper Functions\n",
        "import numpy as np\n",
        "import scipy.fftpack as fft\n",
        "def get_fft(rate, data):\n",
        "    sample_length = len(data)\n",
        "    k = np.arange(sample_length)\n",
        "    period = sample_length / rate\n",
        "    freqs = (k / period)[range(sample_length // 2)] #right-side frequency range\n",
        "    fourier = abs(fft.fft(data * np.hanning(sample_length)) / sample_length) #normalized, not clipped\n",
        "    fourier = fourier[range(sample_length // 2)] #clip to right-side\n",
        "    power = np.power(fourier, 2.0)\n",
        "    return power, freqs\n",
        "\n",
        "def average_frequency(rate, data):\n",
        "    power, freqs = get_fft(rate, data)\n",
        "    #plt.plot(freqs, power)\n",
        "    #plt.show()\n",
        "    return sum(power * freqs) / sum(power)\n",
        "\n",
        "def median_frequency(rate, data):\n",
        "    power, freqs = get_fft(rate, data)\n",
        "    i = 0\n",
        "    highestValue = power[0]\n",
        "    highestIndex = 0\n",
        "    while i < len(power):\n",
        "        if (power[i] > highestValue):\n",
        "            highestIndex = i\n",
        "            highestValue = power[i]\n",
        "        i += 1\n",
        "    return freqs[highestIndex]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKnYIX-AmxyI"
      },
      "source": [
        "!pip install SpeechRecognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6715_FmGRYnN"
      },
      "source": [
        "#@title Key, Tempo, Frequency components\n",
        "import music21\n",
        "import os\n",
        "import librosa\n",
        "file_names = ['bass.mid', 'vocals.mid', 'other.mid']\n",
        "\n",
        "for song in songs:\n",
        "  os.chdir(root + song)\n",
        "  highestKey = None\n",
        "  highestProbability = 0\n",
        "  print(f'Features for song {song} are:')\n",
        "  for midi in file_names:\n",
        "    score = music21.converter.parse('./midi/' + midi)\n",
        "    key = score.analyze('Krumhansl')\n",
        "    #print(f'Results for {song_path + midi}')\n",
        "    #print(f'Key {key} has probability {key.correlationCoefficient}')\n",
        "    if (key.correlationCoefficient > highestProbability):\n",
        "      highestKey = key\n",
        "      highestProbability = key.correlationCoefficient\n",
        "    for altKey in key.alternateInterpretations:\n",
        "      if(altKey.correlationCoefficient < 0.5):\n",
        "        break\n",
        "\n",
        "  #print(f'Most likely key is {highestKey} with probability {highestProbability}')\n",
        "  y, sample_rate = librosa.load(song + '.wav')\n",
        "\n",
        "  # 3. Run the default beat tracker\n",
        "  tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sample_rate)\n",
        "\n",
        "\n",
        "  sample_rate_string = f'Sample rate is {sample_rate}\\n'\n",
        "  key_string = f'Key is {highestKey}\\n'\n",
        "  tempo_string = 'Tempo is {:.2f} beats per minute\\n'.format(tempo)\n",
        "  av_freq_string = 'Average frequency is {:.2f}Hz\\n'.format(average_frequency(sr, y))\n",
        "  median_freq_string = 'Median frequency is {:.2f}Hz\\n'.format(median_frequency(sr, y))\n",
        "  print\n",
        "  print(sample_rate_string)\n",
        "  print(key_string)\n",
        "  print(tempo_string)\n",
        "  print(av_freq_string)\n",
        "  print(median_freq_string)\n",
        "  #Save file\n",
        "  f = open(\"./Features.txt\", \"w\")\n",
        "  f.write(\"Transcription: \" + transcript)\n",
        "  f.write(sample_rate_string)\n",
        "  f.write(key_string)\n",
        "  f.write(tempo_string)\n",
        "  f.write(av_freq_string)\n",
        "  f.write(median_freq_string)\n",
        "  f.close()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNuxwTx1aBDr",
        "outputId": "e5356d4c-af87-4b4a-8963-f00a7a08257b"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/audio_files/Unmix Demo/Vanilla-Ice-Ice-Ice-Baby/\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/16Ktb_bUzQ3didLw2EAmzipUs8iqQYF2Q/audio_files/Unmix Demo/Vanilla-Ice-Ice-Ice-Baby\n",
            "Features.txt  Vanilla-Ice-Ice-Ice-Baby_umxhq\n",
            "midi\t      Vanilla-Ice-Ice-Ice-Baby.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifgsra1_aCtW",
        "outputId": "813643a7-4b66-4fb5-f0de-38aeae84964f"
      },
      "source": [
        "from MIDI import MIDIFile\n",
        "c=MIDIFile(root+songs[0] + '/midi/0C_vocals.mid')\n",
        "c.parse()\n",
        "print(str(c))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Format 1 nTracks 2 division 1024\n",
            "\tTrack 0 of length 0\n",
            "\tTrack 1 of length 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}